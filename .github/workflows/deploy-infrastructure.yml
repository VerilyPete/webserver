# .github/workflows/deploy-infrastructure.yml
name: Deploy Web Infrastructure

on:
  workflow_dispatch:
    inputs:
      deploy_type:
        description: 'Deployment type'
        required: true
        default: 'update'
        type: choice
        options:
          - update
          - fresh_deploy
      hostname:
        description: 'Custom hostname (optional)'
        required: false
        type: string

env:
  OCI_CLI_USER: ${{ secrets.OCI_CLI_USER }}
  OCI_CLI_TENANCY: ${{ secrets.OCI_CLI_TENANCY }}
  OCI_CLI_FINGERPRINT: ${{ secrets.OCI_CLI_FINGERPRINT }}
  OCI_CLI_KEY_CONTENT: ${{ secrets.OCI_CLI_KEY_CONTENT }}
  OCI_CLI_REGION: ${{ secrets.OCI_CLI_REGION }}

jobs:
  deploy:
    runs-on: ubuntu-latest
    timeout-minutes: 45  # Increased to accommodate cloud-init delays
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Generate unique hostname
        id: hostname
        run: |
          if [ -n "${{ github.event.inputs.hostname }}" ]; then
            echo "hostname=${{ github.event.inputs.hostname }}" >> $GITHUB_OUTPUT
          else
            echo "hostname=web-server-$(date +%Y%m%d-%H%M%S)" >> $GITHUB_OUTPUT
          fi

      - name: Deploy new instance (fresh deploy)
        if: github.event.inputs.deploy_type == 'fresh_deploy' || github.event_name == 'workflow_dispatch'
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 20  # Increased timeout for instance creation
        id: create_instance
        with:
          command: 'compute instance launch --availability-domain "${{ secrets.OCI_AVAILABILITY_DOMAIN }}" --compartment-id "${{ secrets.OCI_COMPARTMENT_ID }}" --shape "VM.Standard.A1.Flex" --shape-config "{\"memoryInGBs\":6,\"ocpus\":1}" --image-id "${{ secrets.OCI_IMAGE_ID }}" --subnet-id "${{ secrets.OCI_SUBNET_ID }}" --user-data-file cloud-init.yml --display-name "${{ steps.hostname.outputs.hostname }}" --metadata "{\"ssh_authorized_keys\":\"${{ secrets.SSH_PUBLIC_KEY }}\",\"TAILSCALE_AUTH_KEY\":\"${{ secrets.TAILSCALE_AUTH_KEY }}\",\"CLOUDFLARE_TUNNEL_TOKEN\":\"${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}\",\"FORMSPREE_ENDPOINT\":\"${{ secrets.FORMSPREE_ENDPOINT }}\",\"HOSTNAME\":\"${{ steps.hostname.outputs.hostname }}\"}" --wait-for-state RUNNING --max-wait-seconds 900'
          silent: false

      - name: Debug environment variables
        if: github.event.inputs.deploy_type == 'update'
        run: |
          echo "=== GitHub Actions Environment ==="
          echo "GITHUB_ACTOR: $GITHUB_ACTOR"
          echo "GITHUB_REPOSITORY: $GITHUB_REPOSITORY"
          
          echo "=== OCI Environment Variables (partial) ==="
          echo "OCI_CLI_USER: ${OCI_CLI_USER:0:25}..."
          echo "OCI_CLI_TENANCY: ${OCI_CLI_TENANCY:0:25}..."
          echo "OCI_CLI_REGION: $OCI_CLI_REGION"
          echo "OCI_CLI_FINGERPRINT: $OCI_CLI_FINGERPRINT"
          
          echo "=== Validating OCID Formats ==="
          if [[ $OCI_CLI_USER == ocid1.user.oc1.* ]]; then
            echo "‚úÖ User OCID format looks correct"
          else
            echo "‚ùå User OCID format looks wrong - should start with 'ocid1.user.oc1.'"
          fi
          
          if [[ $OCI_CLI_TENANCY == ocid1.tenancy.oc1.* ]]; then
            echo "‚úÖ Tenancy OCID format looks correct"  
          else
            echo "‚ùå Tenancy OCID format looks wrong - should start with 'ocid1.tenancy.oc1.'"
          fi
          
          if [[ $OCI_CLI_FINGERPRINT =~ ^[a-f0-9]{2}(:[a-f0-9]{2}){15}$ ]]; then
            echo "‚úÖ Fingerprint format looks correct"
          else
            echo "‚ùå Fingerprint format looks wrong - should be 16 colon-separated hex pairs"
          fi

      - name: Test basic OCI connectivity
        if: github.event.inputs.deploy_type == 'update'
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 2  # Increased slightly
        continue-on-error: true
        id: test_connection
        with:
          command: 'iam region list'
          silent: false

      - name: Debug OCI connection result
        if: github.event.inputs.deploy_type == 'update'
        run: |
          echo "=== OCI Connection Test Result ==="
          if [ "${{ steps.test_connection.outcome }}" = "success" ]; then
            echo "‚úÖ OCI connection successful"
            echo "Regions output: ${{ steps.test_connection.outputs.output }}"
          else
            echo "‚ùå OCI connection failed"
            echo "This suggests an authentication issue with your OCI credentials"
          fi

      - name: Find existing instance (update)
        if: github.event.inputs.deploy_type == 'update'
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 3  # Increased timeout
        id: find_instance
        continue-on-error: true
        with:
          command: 'compute instance list --compartment-id "${{ secrets.OCI_COMPARTMENT_ID }}" --lifecycle-state RUNNING'
          query: 'data[?contains(\"display-name\", `web-server`)].id | [0]'
          silent: false

      - name: Check if instance was found
        if: github.event.inputs.deploy_type == 'update'
        id: check_instance
        run: |
          INSTANCE_ID="${{ steps.find_instance.outputs.output }}"
          if [ "$INSTANCE_ID" = "null" ] || [ -z "$INSTANCE_ID" ] || [ "$INSTANCE_ID" = '""' ]; then
            echo "No running instance found with 'web-server' in the name"
            echo "found=false" >> $GITHUB_OUTPUT
            echo "instance_id=" >> $GITHUB_OUTPUT
          else
            echo "Found instance ID: $INSTANCE_ID"
            echo "found=true" >> $GITHUB_OUTPUT
            echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT
          fi

      - name: Get instance IP and update (update)
        if: github.event.inputs.deploy_type == 'update' && steps.check_instance.outputs.found == 'true'
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 2
        id: get_instance_ip
        with:
          command: 'compute instance list-vnics --instance-id "${{ steps.check_instance.outputs.instance_id }}"'
          query: 'data[0].\"public-ip\"'

      - name: Setup SSH key for update
        if: github.event.inputs.deploy_type == 'update' && steps.check_instance.outputs.found == 'true'
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          chmod 700 ~/.ssh

      - name: Update existing infrastructure
        if: github.event.inputs.deploy_type == 'update' && steps.check_instance.outputs.found == 'true'
        timeout-minutes: 12  # Increased timeout
        run: |
          PUBLIC_IP="${{ steps.get_instance_ip.outputs.output }}"
          PUBLIC_IP=$(echo $PUBLIC_IP | tr -d '"')
          
          echo "Found instance with IP: $PUBLIC_IP"
          
          # Robust SSH connectivity check
          echo "Waiting for SSH access..."
          SSH_READY=false
          for i in {1..36}; do  # 36 attempts √ó 10 seconds = 6 minutes max
            if timeout 10 ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o BatchMode=yes opc@$PUBLIC_IP "echo 'SSH Ready'" 2>/dev/null; then
              echo "‚úÖ SSH connection successful (attempt $i)"
              SSH_READY=true
              break
            fi
            echo "SSH attempt $i/36 failed, waiting 10 seconds..."
            sleep 10
          done
          
          if [ "$SSH_READY" = "false" ]; then
            echo "‚ùå SSH connection failed after 6 minutes"
            echo "Instance may be down or network issues present"
            exit 1
          fi
          
          # Update the running infrastructure with better error handling
          echo "Updating infrastructure..."
          ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 opc@$PUBLIC_IP << 'EOF'
            set -e  # Exit on any error
            
            echo "Updating repository..."
            cd ~/web-infra
            git pull origin main || {
              echo "‚ùå Git pull failed"
              exit 1
            }
            
            echo "Updating environment variables..."
            export TAILSCALE_AUTH_KEY="${{ secrets.TAILSCALE_AUTH_KEY }}"
            export CLOUDFLARE_TUNNEL_TOKEN="${{ secrets.CLOUDFLARE_TUNNEL_TOKEN }}"
            export FORMSPREE_ENDPOINT="${{ secrets.FORMSPREE_ENDPOINT }}"
            sudo /usr/local/bin/create-env-from-metadata.sh || {
              echo "‚ùå Environment update failed"
              exit 1
            }
            
            echo "Ensuring user systemd prerequisites..."
            # Ensure lingering is enabled for automatic startup
            if ! loginctl show-user opc | grep -q "Linger=yes"; then
              echo "Enabling user lingering..."
              sudo loginctl enable-linger opc
            fi
            
            # Ensure XDG_RUNTIME_DIR is set
            export XDG_RUNTIME_DIR="/run/user/$(id -u)"
            
            # Reload systemd user daemon
            systemctl --user daemon-reload || {
              echo "‚ö†Ô∏è  Could not reload user systemd daemon"
              # Try to start user systemd instance
              sudo systemctl start user@$(id -u).service || true
              sleep 2
              systemctl --user daemon-reload || true
            }
            
            echo "Restarting services..."
            systemctl --user restart web-infra-pod.service || {
              echo "‚ùå Service restart failed"
              echo "Checking service status:"
              systemctl --user status web-infra-pod.service --no-pager || true
              echo "Checking if service file exists:"
              ls -la ~/.config/systemd/user/ || true
              exit 1
            }
            
            # Wait for service to stabilize
            echo "Waiting for services to stabilize..."
            for i in {1..12}; do  # 2 minutes max
              if systemctl --user is-active web-infra-pod.service >/dev/null 2>&1; then
                echo "‚úÖ Service is active (attempt $i)"
                break
              fi
              if [ $i -eq 12 ]; then
                echo "‚ö†Ô∏è Service taking longer than expected to start"
                systemctl --user status web-infra-pod.service --no-pager
              fi
              sleep 10
            done
            
            echo "Final status check:"
            systemctl --user status web-infra-pod.service --no-pager
            podman pod ps
          EOF

      - name: Handle no existing instance
        if: github.event.inputs.deploy_type == 'update' && steps.check_instance.outputs.found == 'false'
        run: |
          echo "‚ùå No running instance found with 'web-server' in the name"
          echo "üí° Use 'fresh_deploy' to create a new instance"
          exit 1

      - name: Debug instance creation output
        if: github.event.inputs.deploy_type == 'fresh_deploy' || github.event_name == 'workflow_dispatch'
        id: parse_instance_id
        run: |
          echo "=== Raw create_instance output ==="
          echo '${{ steps.create_instance.outputs.output }}'
          echo ""
          echo "=== Extracting instance ID ==="
          # Remove outer quotes and unescape the JSON string
          CLEAN_JSON=$(echo '${{ steps.create_instance.outputs.output }}' | sed 's/^"//; s/"$//; s/\\"/"/g')
          echo "Cleaned JSON:"
          echo "$CLEAN_JSON"
          echo ""
          INSTANCE_ID=$(echo "$CLEAN_JSON" | jq -r '.data.id')
          echo "Extracted instance ID: $INSTANCE_ID"
          echo "instance_id=$INSTANCE_ID" >> $GITHUB_OUTPUT

      - name: Display new instance info (fresh deploy)
        if: github.event.inputs.deploy_type == 'fresh_deploy' || github.event_name == 'workflow_dispatch'
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 2
        continue-on-error: true
        with:
          command: 'compute instance get --instance-id "${{ steps.parse_instance_id.outputs.instance_id }}"'
          query: 'data.{id: id, name: \"display-name\", state: \"lifecycle-state\", shape: shape, region: region}'

      - name: Get new instance IP (fresh deploy)
        if: github.event.inputs.deploy_type == 'fresh_deploy' || github.event_name == 'workflow_dispatch'
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 3
        id: get_new_ip
        continue-on-error: true
        with:
          command: 'compute instance list-vnics --instance-id "${{ steps.parse_instance_id.outputs.instance_id }}"'
          query: 'data[0].\"public-ip\"'

      - name: Setup SSH key for fresh deploy
        if: github.event.inputs.deploy_type == 'fresh_deploy' || github.event_name == 'workflow_dispatch'
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          chmod 700 ~/.ssh

      - name: Wait for cloud-init and services to be ready
        if: github.event.inputs.deploy_type == 'fresh_deploy' || github.event_name == 'workflow_dispatch'
        timeout-minutes: 30  # Increased for more thorough cloud-init detection
        run: |
          PUBLIC_IP=$(echo '${{ steps.get_new_ip.outputs.output }}' | tr -d '"')
          echo "Waiting for instance to be fully ready at $PUBLIC_IP..."
          
          # Function to check if SSH is ready
          check_ssh() {
            timeout 10 ssh -o ConnectTimeout=5 -o StrictHostKeyChecking=no -o BatchMode=yes opc@$PUBLIC_IP "echo 'SSH Ready'" >/dev/null 2>&1
          }
          
          # Wait for SSH to be available (up to 8 minutes)
          echo "1. Waiting for SSH access..."
          SSH_READY=false
          for i in {1..48}; do  # 48 attempts √ó 10 seconds = 8 minutes
            if check_ssh; then
              echo "‚úÖ SSH connection successful (attempt $i)"
              SSH_READY=true
              break
            fi
            echo "SSH attempt $i/48 failed, waiting 10 seconds..."
            sleep 10
          done
          
          if [ "$SSH_READY" = "false" ]; then
            echo "‚ùå SSH connection failed after 8 minutes"
            echo "Instance may have failed to start properly"
            exit 1
          fi
          
          # Wait for cloud-init to complete (up to 20 minutes) using multiple reliable methods
          echo "2. Waiting for cloud-init to complete..."
          ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 opc@$PUBLIC_IP '
            echo "Using cloud-init status --wait (most reliable method)..."
            
            # Method 1: Use cloud-init status --wait with timeout (recommended approach)
            if timeout 1200 cloud-init status --wait; then  # 20 minutes timeout
              echo "‚úÖ Cloud-init completed successfully via status --wait"
              sudo cloud-init status --long
            else
              WAIT_EXIT_CODE=$?
              echo "‚ö†Ô∏è  cloud-init status --wait exited with code $WAIT_EXIT_CODE"
              
              if [ $WAIT_EXIT_CODE -eq 124 ]; then
                echo "‚ùå Timeout: cloud-init did not complete within 20 minutes"
              else
                echo "‚ùå Cloud-init reported failure or other issue"
              fi
              
              echo "Checking status and attempting fallback methods..."
              sudo cloud-init status --long || true
              
              # Method 2: Check for completion marker files as fallback
              echo "Checking for completion marker files..."
              if [ -f "/run/cloud-init/result.json" ]; then
                echo "‚úÖ Found /run/cloud-init/result.json - cloud-init appears complete"
                if command -v jq >/dev/null 2>&1; then
                  echo "Result summary:"
                  sudo jq -r ".v1.errors // []" /run/cloud-init/result.json 2>/dev/null || echo "Could not parse result.json"
                fi
              elif [ -f "/var/lib/cloud/instance/boot-finished" ]; then
                echo "‚úÖ Found /var/lib/cloud/instance/boot-finished - cloud-init appears complete"
              else
                echo "‚ö†Ô∏è  No completion markers found"
                
                # Method 3: Check systemd services as final fallback
                echo "Checking systemd service status..."
                ALL_SERVICES_DONE=true
                for service in cloud-init-local cloud-init cloud-config cloud-final; do
                  if systemctl is-active ${service}.service >/dev/null 2>&1; then
                    echo "‚ö†Ô∏è  ${service}.service is still active"
                    ALL_SERVICES_DONE=false
                  elif systemctl is-failed ${service}.service >/dev/null 2>&1; then
                    echo "‚ùå ${service}.service failed"
                    systemctl status ${service}.service --no-pager || true
                  else
                    echo "‚úÖ ${service}.service completed"
                  fi
                done
                
                if [ "$ALL_SERVICES_DONE" = "true" ]; then
                  echo "‚úÖ All cloud-init systemd services completed"
                else
                  echo "‚ö†Ô∏è  Some cloud-init services still running or failed"
                fi
              fi
              
              echo "Proceeding with deployment despite cloud-init concerns..."
            fi
            
            # Final verification and logging
            echo ""
            echo "=== Final Cloud-init Status ==="
            sudo cloud-init status || true
            echo ""
            echo "=== Cloud-init Boot Times ==="
            sudo cloud-init analyze show 2>/dev/null | head -20 || echo "Analysis not available"
          '
          
          # Wait for web infrastructure to start (up to 8 minutes)
          echo "3. Waiting for web infrastructure to start..."
          ssh -o StrictHostKeyChecking=no -o ConnectTimeout=10 opc@$PUBLIC_IP '
            echo "Checking and fixing podman user service prerequisites..."
            
            # 1. Ensure lingering is enabled (critical for boot startup)
            if ! loginctl show-user opc | grep -q "Linger=yes"; then
              echo "Enabling user lingering for boot startup..."
              sudo loginctl enable-linger opc
            else
              echo "‚úÖ User lingering already enabled"
            fi
            
            # 2. Set up proper runtime directory permissions
            if [ ! -d "/run/user/$(id -u)" ]; then
              echo "Creating user runtime directory..."
              sudo mkdir -p "/run/user/$(id -u)"
              sudo chown $(id -u):$(id -g) "/run/user/$(id -u)"
              sudo chmod 700 "/run/user/$(id -u)"
            fi
            
            # 3. Ensure XDG_RUNTIME_DIR is set
            export XDG_RUNTIME_DIR="/run/user/$(id -u)"
            
            # 4. Check if systemd user directory exists
            if [ ! -d "$HOME/.config/systemd/user" ]; then
              echo "Creating systemd user directory..."
              mkdir -p "$HOME/.config/systemd/user"
            fi
            
            # 5. Reload systemd user daemon to pick up any changes
            systemctl --user daemon-reload 2>/dev/null || {
              echo "‚ö†Ô∏è  Could not reload user systemd daemon, trying to start user systemd..."
              # Start user systemd instance if it is not running
              sudo systemctl start user@$(id -u).service || true
              sleep 2
              systemctl --user daemon-reload || true
            }
            
            echo "Checking web infrastructure service status..."
            WEB_READY=false
            for i in {1..24}; do  # 24 attempts √ó 20 seconds = 8 minutes
              # Check if service exists first
              if systemctl --user list-unit-files | grep -q "web-infra-pod.service"; then
                echo "Service file found, checking status..."
                
                if systemctl --user is-active web-infra-pod.service >/dev/null 2>&1; then
                  echo "‚úÖ Web infrastructure is running (attempt $i)"
                  systemctl --user status web-infra-pod.service --no-pager
                  
                  # Verify podman containers are actually running
                  if podman pod ps --format "{{.Status}}" 2>/dev/null | grep -q "Running"; then
                    echo "‚úÖ Podman containers are running"
                    podman pod ps
                  else
                    echo "‚ö†Ô∏è  Service active but no containers running yet..."
                  fi
                  
                  WEB_READY=true
                  break
                elif systemctl --user is-failed web-infra-pod.service >/dev/null 2>&1; then
                  echo "‚ùå Web infrastructure service failed (attempt $i)"
                  echo "Service status:"
                  systemctl --user status web-infra-pod.service --no-pager || true
                  echo "Recent logs:"
                  journalctl --user -u web-infra-pod.service --no-pager -n 10 || true
                  
                  # Try to restart the service
                  if [ $i -le 3 ]; then
                    echo "Attempting to restart service..."
                    systemctl --user restart web-infra-pod.service || true
                  fi
                else
                  echo "Web infrastructure not ready yet (attempt $i/24)..."
                  systemctl --user status web-infra-pod.service --no-pager || true
                fi
              else
                echo "‚ö†Ô∏è  web-infra-pod.service not found (attempt $i/24)"
                echo "Available user services:"
                systemctl --user list-unit-files --type=service | head -10 || true
                
                # Check if cloud-init created the service yet
                if [ -f "$HOME/.config/systemd/user/web-infra-pod.service" ]; then
                  echo "Service file exists, reloading daemon..."
                  systemctl --user daemon-reload || true
                else
                  echo "Service file not created yet by cloud-init"
                fi
              fi
              
              # Show final status if this is the last attempt
              if [ $i -eq 24 ]; then
                echo "‚ö†Ô∏è  Web infrastructure did not start within 8 minutes"
                echo ""
                echo "=== Diagnostics ==="
                echo "User systemd status:"
                systemctl --user status --no-pager || true
                echo ""
                echo "Service file location:"
                ls -la "$HOME/.config/systemd/user/" 2>/dev/null || echo "No user systemd directory"
                echo ""
                echo "Podman status:"
                podman pod ps 2>/dev/null || echo "Podman not working"
                echo ""
                echo "System journal (last 20 lines):"
                journalctl --user -u web-infra-pod.service --no-pager -n 20 2>/dev/null || echo "No service logs"
                echo ""
                echo "Cloud-init logs (last 10 lines):"
                sudo tail -10 /var/log/cloud-init-output.log 2>/dev/null || echo "No cloud-init output log"
              fi
              
              sleep 20
            done
            
            if [ "$WEB_READY" = "false" ]; then
              echo ""
              echo "üîß Troubleshooting Steps:"
              echo "1. Check cloud-init completed: sudo cloud-init status"
              echo "2. Check user systemd: systemctl --user status"
              echo "3. Check podman: podman pod ps"
              echo "4. Check logs: journalctl --user -u web-infra-pod.service"
              echo "5. Manual start: systemctl --user start web-infra-pod.service"
            fi
          '

      - name: Verify deployment
        run: |
          echo "‚úÖ Deployment completed successfully!"
          echo ""
          if [ "${{ github.event.inputs.deploy_type }}" = "fresh_deploy" ] || [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            echo "üÜï New instance created:"
            echo "   Instance ID: ${{ steps.parse_instance_id.outputs.instance_id }}"
            echo "   Public IP: ${{ steps.get_new_ip.outputs.output }}"
            echo "   Hostname: ${{ steps.hostname.outputs.hostname }}"
          else
            echo "üîÑ Existing instance updated:"
            echo "   Instance ID: ${{ steps.check_instance.outputs.instance_id }}"
            echo "   Public IP: ${{ steps.get_instance_ip.outputs.output }}"
          fi
          echo ""
          echo "üîç Check your Tailscale admin console for the device"
          echo "üåê Web server will be accessible at http://[tailscale-ip]:8081"
          echo "üìä Monitor with: ssh opc@[instance-ip] 'podman pod ps'"

  cleanup-old-instances:
    runs-on: ubuntu-latest
    timeout-minutes: 8  # Increased slightly
    needs: deploy
    if: github.event.inputs.deploy_type == 'fresh_deploy'
    
    env:
      OCI_CLI_USER: ${{ secrets.OCI_CLI_USER }}
      OCI_CLI_TENANCY: ${{ secrets.OCI_CLI_TENANCY }}
      OCI_CLI_FINGERPRINT: ${{ secrets.OCI_CLI_FINGERPRINT }}
      OCI_CLI_KEY_CONTENT: ${{ secrets.OCI_CLI_KEY_CONTENT }}
      OCI_CLI_REGION: ${{ secrets.OCI_CLI_REGION }}
    
    steps:
      - name: List old instances for manual cleanup
        uses: oracle-actions/run-oci-cli-command@v1.3.2
        timeout-minutes: 3
        with:
          command: 'compute instance list --compartment-id "${{ secrets.OCI_COMPARTMENT_ID }}" --lifecycle-state RUNNING'
          query: 'data[?contains(\"display-name\", `web-server`)].{Name:\"display-name\", ID:id, Created:\"time-created\"}'
          silent: false

      - name: Cleanup instructions
        run: |
          echo ""
          echo "üßπ Old instances listed above may need cleanup"
          echo "üí° To terminate old instances:"
          echo "   Use the OCI Console or run:"
          echo "   oci compute instance terminate --instance-id <INSTANCE_ID> --force"